{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Efficient SAM Example"
      ],
      "metadata": {
        "id": "xhhr4iSQuQq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script provides example for how to get visualization result from EfficientSAM using ready-to-use torchscript, part of the code is borrow from MobileSAM project, many thanks!"
      ],
      "metadata": {
        "id": "AIrAUKnLClPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "zylNfpYIuXeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I64YhiKsS2KU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Box and Point prompt"
      ],
      "metadata": {
        "id": "pw_4lyT8uMvy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hrhmpHroFUH"
      },
      "outputs": [],
      "source": [
        "def run_ours_point(img_path, pts_sampled, model):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_tensor = ToTensor()(image)\n",
        "    pts_sampled = torch.reshape(torch.tensor(pts_sampled), [1, 1, -1, 2])\n",
        "    max_num_pts = pts_sampled.shape[2]\n",
        "    pts_labels = torch.ones(1, 1, max_num_pts)\n",
        "\n",
        "    predicted_logits, predicted_iou = model(\n",
        "        img_tensor[None, ...].cuda(),\n",
        "        pts_sampled.cuda(),\n",
        "        pts_labels.cuda(),\n",
        "    )\n",
        "    predicted_logits = predicted_logits.cpu()\n",
        "    all_masks = torch.ge(torch.sigmoid(predicted_logits[0, 0, :, :, :]), 0.5).numpy()\n",
        "    predicted_iou = predicted_iou[0, 0, ...].cpu().detach().numpy()\n",
        "\n",
        "    max_predicted_iou = -1\n",
        "    selected_mask_using_predicted_iou = None\n",
        "    for m in range(all_masks.shape[0]):\n",
        "        curr_predicted_iou = predicted_iou[m]\n",
        "        if (\n",
        "            curr_predicted_iou > max_predicted_iou\n",
        "            or selected_mask_using_predicted_iou is None\n",
        "        ):\n",
        "            max_predicted_iou = curr_predicted_iou\n",
        "            selected_mask_using_predicted_iou = all_masks[m]\n",
        "    return selected_mask_using_predicted_iou\n",
        "\n",
        "def run_ours_box(img_path, pts_sampled, model):\n",
        "    bbox = torch.reshape(torch.tensor(pts_sampled), [1, 1, 2, 2])\n",
        "    bbox_labels = torch.reshape(torch.tensor([2, 3]), [1, 1, 2])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    predicted_logits, predicted_iou = model(\n",
        "        img_tensor[None, ...].cuda(),\n",
        "        bbox.cuda(),\n",
        "        bbox_labels.cuda(),\n",
        "    )\n",
        "    predicted_logits = predicted_logits.cpu()\n",
        "    all_masks = torch.ge(torch.sigmoid(predicted_logits[0, 0, :, :, :]), 0.5).numpy()\n",
        "    predicted_iou = predicted_iou[0, 0, ...].cpu().detach().numpy()\n",
        "\n",
        "    max_predicted_iou = -1\n",
        "    selected_mask_using_predicted_iou = None\n",
        "    for m in range(all_masks.shape[0]):\n",
        "        curr_predicted_iou = predicted_iou[m]\n",
        "        if (\n",
        "            curr_predicted_iou > max_predicted_iou\n",
        "            or selected_mask_using_predicted_iou is None\n",
        "        ):\n",
        "            max_predicted_iou = curr_predicted_iou\n",
        "            selected_mask_using_predicted_iou = all_masks[m]\n",
        "    return selected_mask_using_predicted_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization Related"
      ],
      "metadata": {
        "id": "-83WUeNPuJnT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKWt76-AG31h"
      },
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.8])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='yellow', facecolor=(0,0,0,0), lw=5))\n",
        "\n",
        "def show_anns_ours(mask, ax):\n",
        "    ax.set_autoscale_on(False)\n",
        "    img = np.ones((mask[0].shape[0], mask[0].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in mask:\n",
        "        m = ann\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load torchscript models"
      ],
      "metadata": {
        "id": "GHj10cGetlGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download link for torchscript:\n",
        "\n",
        "EfficientSAM-s: https://www.dropbox.com/scl/fi/ziif8xudwbyyphb4tohza/efficientsam_s_gpu.jit?rlkey=8aflq9kf0bfujz5ex4lxuoq56&dl=0\n",
        "\n",
        "EfficientSAM-ti: https://www.dropbox.com/scl/fi/lup5s4gthmlv6qf3f5zz3/efficientsam_ti_gpu.jit?rlkey=pap1xktxw50qiaey17no16bqz&dl=0"
      ],
      "metadata": {
        "id": "OLPFPCuzB4lT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HR4CCpYUpAI"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.load('efficientsam_s_gpu.jit')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Box segmentation"
      ],
      "metadata": {
        "id": "b76-PTdKuidf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepare your own image here"
      ],
      "metadata": {
        "id": "o6ed2uLDCSDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xq7KloryJrhf"
      },
      "outputs": [],
      "source": [
        "input_point = np.array([[100, 100], [300, 300]])\n",
        "input_label = np.array([1])\n",
        "image_path = './xxx.jpg'\n",
        "\n",
        "mask_ours = run_ours_box(image_path, input_point, model)\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image)\n",
        "show_anns_ours(mask_ours, plt.gca())\n",
        "plt.title(f\"EfficientSAM\", fontsize=18)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Point segmentation"
      ],
      "metadata": {
        "id": "6IQBINppEQXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jpWTIwoNG452"
      },
      "outputs": [],
      "source": [
        "input_point = np.array([[400, 400]])\n",
        "input_label = np.array([1])\n",
        "image_path = './xxx.jpg'\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask = run_ours_point(image_path, input_point, model)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "show_mask(mask, plt.gca())\n",
        "show_points(input_point, input_label, plt.gca())\n",
        "plt.title(f\"EfficientSAM\", fontsize=18)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
